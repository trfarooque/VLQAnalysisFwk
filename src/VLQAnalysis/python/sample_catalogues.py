"""
This module provides catalogues to interact with the samples.

All samples are initially provided in a txt file corresponding to one
production (the file `datasets_to_download.txt` provided by Peyton).

SampleCatalogue is the main class here. It takes care of:

- organizing the samples in categories: data, ttbar, signal,
  etc. Categories are flexible (just list of files) and they should be
  implemented following the `categorise_samples` example.
- attaching systematic uncertainties to the samples
- attaching ChainProvider(s) to the Variation
- TODO building the VLQAnalysis/data/samples_info.dat file

Overall design:
A Sample has a list of SystematicUncertainty; the 'nominal' case is
just a SystematicUncertainty.is_nominal.
Each uncertainty has one or two Variation.
Each Variation has access to the input chain through a filelist
generated by InputDataInterface

Different analyses might need to access different samples, or to
organize them in different ways (e.g. special treatment of signal
samples, systematic samples, etc.). This is implemented by
specializing SampleCatalogue.

Example usage:

# Step 0
# If you start from a 'production sample list' --> build group files
#  > sc = VlqSampleCatalogue() # or HbsmSampleCatalogue
#  > sc.verbose = True
#  > sc.add_samples_from_file(path='VLQAnalysis/data/samples_HtX4TopsNtuple-00-00-12.txt')
#  > sc.categorise_samples(sc.samples)
#  > sc.write_group_files()

# Step 1
# Otherwise start from existing group files
#  > sc.add_samples_from_group_files(sc.groupfiles_directory+'/*.txt'))

# Step 2
# Write filelists; the input can be either a local dir or a storage interface (eos, pnfs, ...)
#  > input_from_dir = LocalDiskInterface(filelist_dir='VLQAnalysis/data/filelist',
#  >                                     base_input_dir='/tmp/gerbaudo/rucio')
#  > input_from_eos = RucioEosCernInterface()
#  > sc.add_filelists(samples=sc.samples, input_interface=input_from_eos)

# Note1: the filelists are attached to each 'Variation' (not to each 'Sample').
# Note2: sample-specific job options can be inserted in the txt files
#        (as in MultibjetsAnalysis, with the '# config:' comment)
# Now you can start processing the samples.
# See instructions in hbsm_submit.py

TODO : implement special treatment of systematic samples.
TODO : speedup the generation of filelists? (rucio can take hrs w/out
       multiprocessing, local disk is fine)

davide.gerbaudo@gmail.com
Jul 2016
"""

import copy
import glob
import os
import re
import collections

from VLQAnalysis import utils

import systematics # perhaps the catalogue should be instantiated elsewhere (e.g. if it will become a specialised catalogue?)
catalogue = systematics.SystematicCatalogue()


#___________________________________________________________

class Sample(object):
    """Holds info about a sample and its attributes.
    'full_name' is always there; the other attributes are filled as needed.
    """
    def __init__(self, short_name=None, full_name=None, group=None,
                 job_options=None,
                 filelist_dir=None, filelist_file=None,
                 ds_input=None):
        self.short_name = short_name
        self.full_name = full_name
        self._group = group
        self.job_options = job_options
        self.ds_input = ds_input
        self.systematic_uncertainties = [catalogue.nominal()]
        if not full_name:
            raise ValueError("Sample must have full_name")

    def __str__(self):
        plain_attrs = ['short_name', 'full_name', 'group', 'ds_input']
        # TODO how do you want to print the uncertainties (and the chainprovider)
        return "Sample :"+ ', '.join("%s : '%s'" % (a, va) for a, va in [(pa, getattr(self, pa)) for pa in plain_attrs] if va)

    @property
    def dsid(self, verbose=False):
        "No need to input this by hand, just extract it from full_name"
        return utils.guess_id_from_name(samplename=self.full_name, verbose=verbose)

    @property
    def group(self):
        return self._group

    @group.setter
    def group(self, value):
        "this attribute is set by SampleCatalogue so we need to check it and cache it"
        if not self._group or self._group==value:
            self._group = value
        else:
            print "overwriting sample group from %s to %s" % (self._group, value)
            self._group = value

    def use_all_uncertainties(self):
        self.systematic_uncertainties = catalogue.all_uncertainties()

    def use_object_uncertainties(self):
        self.systematic_uncertainties = catalogue.object_uncertainties()

    def use_weight_uncertainties(self):
        self.systematic_uncertainties = catalogue.weight_uncertainties()

    def use_nominal_uncertainty(self):
        "nothing to do, this is the default"
        pass
#___________________________________________________________

class SampleCatalogue(object):
    """Keep track of a collection of samples.

    Samples can be added to the catalogue in two ways:

    - either from a single file, in which case they will not have a
      'group' until `categorise_samples()` is called. This is typically
      used when we move to a new production and all the files are just
      listed in a file.

    - or from several files group files, in which case the filename is
      used as the group

    In general one builds the catalogue from the group files.

    TODO attach syst uncertainties to samples

    """
    keyword_job_option = 'config:' # same convention as in MultibjetsAnalysis

    def __init__(self):
        self.samples = []
        self.verbose = False
        self.groupfiles_directory = 'VLQAnalysis/data/groups' # should be overwritten by specific catalogue

    def add_samples_from_group_files(self, paths=[]):
        """This is the usual method to populate the catalogue, from
        samples that have altready been organised in groups.
        The name of each group is determined from the filename
        Example:
        > catalogue.add_samples_categorised(glob.glob('path/to/files/*.txt')
        """
        for path in paths:
            group = utils.filename_without_extension(path)
            self.add_samples_from_file(path, group=group)

    def add_samples_from_file(self, path, group=None):
        """This should be used to populate the catalogue when you have a
        new production. path should be the file 'datasets_to_download.txt'
        generated from HtX4TopsNtuple.
        """
        job_options = None
        keyword_job_option = SampleCatalogue.keyword_job_option
        for line in SampleCatalogue.read_lines_from_txt(path, keywords_useful_comment_line=[keyword_job_option]):
            if keyword_job_option in line:
                job_options = line[line.find(keyword_job_option)+len(keyword_job_option):].strip()
                continue # will affect all upcoming samples
            self.samples.append(Sample(full_name=line, group=group, job_options=job_options))

    def write_group_files(self, allow_uncategorised_samples=True):
        """After having called 'categorise_samples', you can write the samples organised in group files.
        Alternatively, you can also just write your group files by hand.
        """
        num_uncategorised_samples = len(self.uncategorised_samples)
        if num_uncategorised_samples:
            print ("Warning: there are %d samples that do not belong to any group." % num_uncategorised_samples
                   +" Please check 'uncategorised.txt'")
            if not allow_uncategorised_samples:
                uncategorised = [s for s in self.samples if not s.group]
                raise NotImplementedError("Do not know how to handle uncategorised samples:\n"+
                                          '\n'.join(s.full_name for s in uncategorised))
        utils.mkdir_if_needed(self.groupfiles_directory)
        samples_per_group = collections.defaultdict(list)
        samples_per_group['uncategorised'] = []
        for s in self.samples:
            if not s.group:
                samples_per_group['uncategorised'].append(s)
            else:
                samples_per_group[s.group].append(s)
        if not samples_per_group['uncategorised']:
            samples_per_group.pop('uncategorised', None)
        for group, samples in samples_per_group.items():
            filename = os.path.join(self.groupfiles_directory, group+'.txt')
            with open(filename, 'w') as output_file:
                output_file.write('\n'.join(s.full_name for s in samples))
            if self.verbose:
                print "written %s" % filename
    @classmethod
    def categorise_samples(cls, samples):
        raise NotImplementedError("This operation depends on the analysis,"
                                  " and it is implemented only in the specialised catalogues")
    @classmethod
    def add_systematic_variations(cls, samples):
        raise NotImplementedError("This operation depends on the analysis,"
                                  " and it is implemented only in the specialised catalogues")
    @property
    def uncategorised_samples(self):
        return [s for s in self.samples if not s.group]

    @property
    def groups(self):
        return sorted(list(set(s.group for s in self.samples if s.group)))

    def samples_from_group(self, group=''):
        return [s for s in self.samples if s.group==group]

    @classmethod
    def determine_group_from_name(cls, sample=None):
        """Determine the group of this sample from its name.

        This is where the analysis-specific catalogues can implement their categorisation.
        """
        group = ('data' if cls.is_data(sample) else
                'ttbar' if cls.is_ttbar(sample) else
                'wjets' if cls.is_wjets(sample) else
                'zjets' if cls.is_zjets(sample) else
                'singletop' if cls.is_singletop(sample) else
                'diboson' if cls.is_diboson(sample) else
                'topewk' if cls.is_topewk(sample) else
                'tth' if cls.is_tth(sample) else
                'fourtop' if cls.is_fourtop(sample) else
                'FCNC' if cls.is_fcnc(sample) else
                'Hplus_lm' if cls.is_hplus(sample) else 
                None)
        return group

    @staticmethod
    def is_data(sample):
        return 'physics_Main' in sample.full_name

    @staticmethod
    def is_ttbar(sample):
        return any(str(dsid) in sample.full_name for dsid in range(407009, 407012+1) + range(410000, 410004+1) + [410120])

    @staticmethod
    def is_wjets(sample):
        return any(str(dsid) in sample.full_name
                   for dsid in range(361300, 361371+1) + range(363331, 363483+1) )

    @staticmethod
    def is_zjets(sample):
        return any(str(dsid) in sample.full_name for dsid in range(361372, 361443+1)
                   +[363102, 363105, 363108, 363111, 363114, 363117]
                   +[363120, 363103, 363106, 363109, 363112, 363115,]
                   +[363118, 363121, 363104, 363107, 363110, 363113, 363116, 363119]
                   )

    @staticmethod
    def is_singletop(sample):
        return any(str(dsid) in sample.full_name for dsid in range(410011, 410016+1) + [410025, 410026])

    @staticmethod
    def is_diboson(sample):
        return any(str(dsid) in sample.full_name for dsid in range(361091, 361097+1))

    @staticmethod
    def is_topewk(sample):
        return any(str(dsid) in sample.full_name
                   for dsid in range(410111, 410116+1) + [410066, 410067, 410068] + [410073, 410074, 410075] + [410081])

    @staticmethod
    def is_tth(sample):
        return any(str(dsid) in sample.full_name for dsid in [343365, 343366, 343367])

    @staticmethod
    def is_fourtop(sample):
        return any(str(dsid) in sample.full_name for dsid in [410080])

    @staticmethod
    def is_fcnc(sample):
        return any(str(dsid) in sample.full_name for dsid in range(410696,410699+1))
       
    @staticmethod
    def is_hplus_lm(sample):
        return any(str(dsid) in sample.full_name for dsid in range(345081,345095+1)+[345284, 345285])     

    @staticmethod
    def read_lines_from_txt(txt_filename, keywords_useful_comment_line=[]):
        "parse a file dropping comment and empty lines"
        def is_comment_or_empty(l):
            l = l.strip()
            return not l or l.startswith('#')
        lines = []
        with open(txt_filename) as f:
            lines = [l.strip() for l in f.readlines()
                     if not is_comment_or_empty(l)
                     or any(k in l for k in keywords_useful_comment_line)]
        return lines

    def write_script_to_generate_rucio_eos_lists(self, script_filename='generate_eos_filelists.sh',
                                                 output_directory='./', rse='CERN-PROD_SCRATCHDISK'):
        """Obsolete, please use SampleCatalogue.add_filelists

        I cannot execute the rucio commands in the same shell where I
        run python, so I have to write them out to a file.
        """
        raise NotImplementedError("Obsolete, please use SampleCatalogue.add_filelists")
        tmp_samplelist = '/tmp/samples.txt'
        with open(script_filename, 'w') as of:
            of.write('#!/bin/bash\n')
            of.write('# open a shell with rucio, then execute the commands below\n')
            of.write('mkdir -p '+output_directory+'\n')
            of.write('cd '+output_directory+'\n')
            of.write('cat << EOF > '+tmp_samplelist+'\n')
            of.write('\n'.join(s.full_name for s in self.samples)+'\n')
            of.write('EOF\n')
            of.write('\n')
            of.write('RSE="'+rse+'"\n')
            of.write('for X in `cat '+tmp_samplelist+'`\n')
            of.write('do''\n')
            of.write("    rucio list-file-replicas --rse ${RSE} ${X}"
                     " | grep ${RSE} | awk '{print $12}'" # extract filename
                     " | sed 's@.*eos@root://eosatlas//eos@'" # prepend protocol (replace '/eos' with 'root://eosatlas//eos')
                     " > `basename ${X}`.txt"+'\n') # strip trailing /
            of.write('done \n')
            of.write('cd - \n')
        print "To generate the file lists, open a new shell with rucio, then execute 'source %s'" % script_filename
    def prune_samples(self, regex_include=None, regex_exclude=None):
        """filter samples with two input regex that are applied to the
        short name (if available) or to the full_name"""
        self.samples = (utils.filter_with_regexp(self.samples, regex_include,
                                                 func=lambda x: x.short_name if x.short_name else x.full_name)
                        if regex_include else self.samples)
        self.samples = (utils.exclude_with_regexp(self.samples, regex_exclude,
                                                  func=lambda x: x.short_name if x.short_name else x.full_name)
                        if regex_exclude else self.samples)


#___________________________________________________________

class VlqSampleCatalogue(SampleCatalogue):
    "Catalogue with features that are specific to the VLQ analysis"

    def __init__(self):
        super(VlqSampleCatalogue, self).__init__()
        self.groupfiles_directory = 'VLQAnalysis/data/groups/vlq'

    @classmethod
    def determine_group_from_name(cls, sample=None):
        """Determine the group of this sample from its.

        This is where the analysis-specific catalogues can implement their categorisation.
        """
        group = ('vlq' if cls.is_vlq(sample) else
                 'uerdpp' if cls.is_uerdpp(sample) else
                 'fourtopci' if cls.is_fourtopci(sample) else
                 SampleCatalogue.determine_group_from_name(sample))
        return group

    @classmethod
    def categorise_samples(cls, samples, overwrite_group=False, verbose=False):
        """This is where the samples are organised in groups.

        For some groups we might need to perform extra steps; for
        example we need to assign the 'short_name' (this was called
        'name' in VLQ_Samples.py)
        """
        for sample in samples:
            sample.group = cls.determine_group_from_name(sample)
            if sample.group == 'vlq':
                sample.short_name = cls.vlq_short_name(sample)
            elif sample.group == 'uerdpp':
                sample.short_name = cls.uerdpp_short_name(sample)
            elif sample.group == 'fourtopci':
                sample.short_name = '4tops_CI'

    @staticmethod
    def is_vlq(sample):
        return any(str(dsid) in sample.full_name for dsid in range(302468, 302519+1))

    @staticmethod
    def is_uerdpp(sample):
        return any(str(dsid) in sample.full_name for dsid in range(302055, 302059+1))

    @staticmethod
    def is_fourtopci(sample):
        return any(str(dsid) in sample.full_name for dsid in [302777])

    @classmethod
    def vlq_short_name(cls, sample=None):
        dsid = int(sample.dsid)
        return ('VLQ_TT_600'  if dsid==302469 else
                'VLQ_TT_700'  if dsid==302470 else
                'VLQ_TT_750'  if dsid==302471 else
                'VLQ_TT_800'  if dsid==302472 else
                'VLQ_TT_850'  if dsid==302473 else
                'VLQ_TT_900'  if dsid==302474 else
                'VLQ_TT_950'  if dsid==302475 else
                'VLQ_TT_1000' if dsid==302476 else
                'VLQ_TT_1050' if dsid==302477 else
                'VLQ_TT_1100' if dsid==302478 else
                'VLQ_TT_1150' if dsid==302479 else
                'VLQ_TT_1200' if dsid==302480 else
                'VLQ_TT_1300' if dsid==302481 else
                'VLQ_TT_1400' if dsid==302482 else
                None)

    @classmethod
    def uerdpp_short_name(cls, sample=None):
        dsid = int(sample.dsid)
        return ('UEDRPP_1000' if dsid==302055 else
                'UEDRPP_1200' if dsid==302056 else
                'UEDRPP_1400' if dsid==302057 else
                'UEDRPP_1600' if dsid==302058 else
                'UEDRPP_1800' if dsid==302059 else
                None)

#___________________________________________________________

class HbsmSampleCatalogue(SampleCatalogue):
    "Catalogue with features that are specific to the HBSM analysis"

    def __init__(self):
        super(HbsmSampleCatalogue, self).__init__()
        self.groupfiles_directory = 'VLQAnalysis/data/groups/hbsm'

    @classmethod
    def determine_group_from_name(cls, sample=None):
        """Determine the group of this sample from its.

        This is where the analysis-specific catalogues can implement their categorisation.
        """
        group = ('hbsm' if cls.is_hbsm(sample) else
                 SampleCatalogue.determine_group_from_name(sample))
        return group

    @classmethod
    def categorise_samples(cls, samples, overwrite_group=False, verbose=False):
        """This is where the samples are organised in groups.

        For some groups we might need to perform extra steps; for
        example we need to assign the 'short_name' (this was called
        'name' in VLQ_Samples.py)
        """
        for sample in samples:
            sample.group = cls.determine_group_from_name(sample)
            if sample.group == 'hbsm':
                sample.short_name = cls.hbsm_short_name(sample)

    @staticmethod
    def is_hbsm(sample):
        return any(str(dsid) in sample.full_name
                   for dsid in range(344066, 344081+1) + range(341545, 341558+1) + [343434, 343432] + range(304777, 304780+1) + range(344896,344900+1) + range(344902,344904+1))
    @classmethod
    def hbsm_short_name(cls, sample=None):
        dsid = int(sample.dsid)
        return ('VLQ_TT_600'  if dsid==302469 else
                'VLQ_TT_700'  if dsid==302470 else
                'VLQ_TT_750'  if dsid==302471 else
                'VLQ_TT_800'  if dsid==302472 else
                'VLQ_TT_850'  if dsid==302473 else
                'VLQ_TT_900'  if dsid==302474 else
                'VLQ_TT_950'  if dsid==302475 else
                'VLQ_TT_1000' if dsid==302476 else
                'VLQ_TT_1050' if dsid==302477 else
                'VLQ_TT_1100' if dsid==302478 else
                'VLQ_TT_1150' if dsid==302479 else
                'VLQ_TT_1200' if dsid==302480 else
                'VLQ_TT_1300' if dsid==302481 else
                'VLQ_TT_1400' if dsid==302482 else
                None)

    @classmethod
    def add_systematic_variations(cls, samples=None, verbose=False, syst_option=False):
        """Here we might need to add/drop samples, so we will just
        re-build the list dealing with the groups one at the time
        """
        weight_only = syst_option and syst_option=='weight'
        object_only = syst_option and syst_option=='object'
        if syst_option and syst_option not in ['weight', 'object', 'all']:
            raise NotImplementedError("for now can only accept either weight|object|all, not '%s'" % syst_option)
        updated_samples = []
        samples_per_group = collections.defaultdict(list)
        for sample in samples:
            samples_per_group[sample.group].append(sample)
        for group, samples in samples_per_group.iteritems():
            if group=='data':
                updated_samples += samples
            elif group=='ttbar':
                if verbose:
                    print 'adding ttbar systematics'
                updated_samples += cls.add_ttbar_systematics(samples)
            else:
                if verbose:
                    print 'adding other systematics'
                updated_samples += cls.add_generic_systematics(samples,
                                                               weight_only=weight_only,
                                                               object_only=object_only)
            # do we need to do anything special for the signals?
            # TODO filter systematics with comma-sep list from syst_option
            # TODO filter systematics with refex
        return updated_samples

    @staticmethod
    def add_ttbar_systematics(ttbar_samples, weight_only=False, object_only=False):
        """Take a list of samples and provide a new list containing
        samples with syst uncertainties (and additional samples if
        needed when splitting in hf).
        """
        print "add_ttbar_systematics: weight_only, object_only not implemented yet"
        updated_samples = []
        hf_splitted = True # should it be configurable?  in this case we need to process n times the samples
        use_ht_slices = True # should it be configurable? in this case we need to process more samples
        ht_sliced_dsids = [410000, 407009, 407010, 407011, 407012] # low, 1, 2, 3, met
        ht_sliced_samples = [s for s in ttbar_samples if int(s.dsid) in ht_sliced_dsids]
        ht_inclusive_samples = [s for s in ht_sliced_samples if int(s.dsid)==41000]

        if hf_splitted: # this only implements the 'simple' splitting of VLQ_Samples.py
            samples_to_split_in_hf = ht_sliced_samples if use_ht_slices else ht_inclusive_samples
            hf_slices = ['light', 'bb', 'cc']
            for hf_slice in hf_slices: # need to make a copy of the samples b/c they will be processed 3 times
                samples_this_slice = [copy.deepcopy(s) for s in samples_to_split_in_hf]
                for s in samples_this_slice:
                    s.short_name = 'ttbar'+hf_slice
                updated_samples += samples_this_slice
        elif use_ht_slices:
            updated_samples += ht_sliced_samples
        else:
            raise NotImplementedError("add_ttbar_systematics not implemented w/out slices, see VLQ_Samples.py")
        for s in updated_samples: # TODO check with Loic+Mirko that this is always needed
            s.use_all_uncertainties()
        return updated_samples

    @staticmethod
    def add_generic_systematics(samples, weight_only=False, object_only=False):
        "Toggle on the weight and object systematic variations"
        if weight_only:
            for s in samples:
                s.use_weight_uncertainties()
        elif object_only:
            for s in samples:
                s.use_object_uncertainties()
        else:
            for s in samples:
                s.use_all_uncertainties()
        return samples

#___________________________________________________________

class InputDataInterface(object):
    """Base class defining how we access input data (through filelists).

    In general one should just call 'filelist()'; some interfaces
    (e.g. disk) will automatically generate it if it's not there;
    others (e.g. eos, rse) will tell you how to generate it. The
    second behaviour is motivated by the fact that the generation
    might take time (e.g. eos) or special setup (e.g. rucio), so it
    might be better to do this asynchronously, once for all samples in
    a separate shell.

    For an example of the second case, see
    'SampleCatalogue.add_filelists'.

    For tests, one can also call
    'InputDataInterface.generate_filelist' for a single sample (rather
    than trough the catalogue).
    """
    def __init__(self, filelist_dir):
        self.filelist_dir = utils.mkdir_if_needed(filelist_dir)
    def generate_filelist(self, container):
        raise NotImplementedError("Should be implemented in specialised classes")
    def filelist(self, container):
        raise NotImplementedError("Should be implemented in specialised classes")

    def attach_filelists(self, samples=[], verbose=False):
        "Attach a filelist to each one of the input samples x variations"
        if verbose:
            print "About to check/create filelists for %d samples; this might take some time." % len(samples)
        for sa in samples:
            for su in sa.systematic_uncertainties:
                for v in su.variations:
                    v.filelist = str(self.generate_filelist(sa.full_name))
                    if verbose:
                        n_files = sum(1 for l in open(v.filelist).readlines() if not l.strip().startswith('#'))
                        print "%s added filelist (%d files) %s %s" % (self.filelist_dir,
                                                                      n_files,
                                                                      sa.full_name,
                                                                      '', #sys not needed for now
                                                                      )
                    # note to self: here sample knows about the
                    # container name, and variation knows about the
                    # treename. It assumes that the object variation
                    # trees are in the same file as the nominal one.
                    # I might need to revise this when we start using
                    # systematic samples?
        # return samples

#___________________________________________________________

class LocalDiskInterface(InputDataInterface):
    """Data on disk that can be accessed through simple os.path.
    If there is no filelist just generate it.
    It assumes that there is one sub-directory for each container.
    """
    def __init__(self, filelist_dir=None, base_input_dir=None):
        super(LocalDiskInterface, self).__init__(filelist_dir)
        self.base_input_dir = base_input_dir

    def generate_filelist(self, container):
        container = container.strip('/')
        filelist_path = os.path.join(self.filelist_dir, container+'.txt')
        if not os.path.exists(filelist_path):
            with open(filelist_path, 'w') as filelist_file:
                filenames = [f for f in os.listdir(os.path.join(self.base_input_dir, container))
                             if '.root' in f]
                filenames = sorted(filenames)
                filenames = [os.path.abspath(os.path.join(self.base_input_dir, container, f))
                             for f in filenames]
                filelist_file.write('\n'.join(filenames)+'\n')
        return filelist_path

    def filelist(self, container):
        filelist_path = os.path.join(self.filelist_dir, container.strip('/')+'.txt')
        if not os.path.exists(filelist_path):
            self.generate_filelist(container)
        return filelist_path

#___________________________________________________________

class At3ScratchDiskInterface(LocalDiskInterface):
    """Data downloaded to the scratch2 disk on at3.
    Currently 00-10 production.
    """
    def __init__(self,
                 filelist_dir='VLQAnalysis/data/hbsm/filelist/at3pnfs',
                 base_input_dir='/nfs/at3/scratch2/lvalery/VLQFiles/AT-00-00-10/'):
        super(At3ScratchDiskInterface, self).__init__(filelist_dir, base_input_dir)

#___________________________________________________________

class EosUserInterface(InputDataInterface):
    """Data on eos accessed through 'eos ls' (not via rucio).
    When the filelist if missing, raise IOError.
    Prefer not to generate them under the hood (can take time, better
    if user does it explicitly).
    """
    def __init__(self, filelist_dir, base_input_dir):
        super(EosUserInterface, self).__init__(filelist_dir)
        self.base_input_dir = base_input_dir

    def filelist(self, container):
        container = container.strip('/')
        filelist_path = os.path.join(self.filelist_dir, container+'.txt')
        if not os.path.exists(filelist_path):
            raise IOError("Missing filelist from EosUserInterface(%s) for %s" % (self.filelist_dir, container)
                          +"Probably need to call SampleCatalogue.add_filelists()")
        return filelist_path

    def generate_filelist(self, container):
        raise NotImplementedError("Need some cleanup of the output? and perhaps pre-pend 'root://eosatlas//eo'")
        # todo include lines below
        container = container.strip('/')
        cmd = "eos ls %s/%s" % (self.base_input_dir, container)
        utils.get_command_output(cmd)
        filelist_path = os.path.join(self.filelist_dir, container+'.txt')
        with open(filelist_path, 'w') as filelist_file:
            filenames = [f for f in os.listdir(os.path.join(self.base_input_dir, container)) if '.root' in f]
            filelist_file.write('\n'.join(filenames))
        return filelist_path

#___________________________________________________________

class RseInterface(InputDataInterface):
    """Interface to a remote storage element accessed through rucio.
    When the filelist if missing, raise IOError.
    Prefer not to generate them under the hood (can take time, better
    if user does it explicitly).

    Users should usually instantiate objects of site-specific classes
    (see RucioEosCernInterface and RucioPnfsIfaeInterface)
    """
    def __init__(self, filelist_dir, rse, root_prefix, root_prefix_placeholder):
        """
        Example arguments:
        - rse : CERN-PROD_SCRATCHDISK
        - root_prefix : root://eosatlas//eos
        - root_prefix_placeholder : eos
        See generate_filelist.clean_line for details
        """
        super(RseInterface, self).__init__(filelist_dir)
        self.rse = rse
        self.root_prefix = root_prefix
        self.root_prefix_placeholder = root_prefix_placeholder

    def filelist(self, container):
        filelist_path = os.path.join(self.filelist_dir, container.strip('/')+'.txt')
        if not os.path.exists(filelist_path):
            raise IOError("Missing filelist from RseUserInterface(%s) for %s" % (self.filelist_dir, container)
                          +"Probably need to call SampleCatalogue.add_filelists()")
        return filelist_path

    def generate_filelist(self, container, overwrite_filelist=False):
        container = container.strip('/')
        filelist_path = os.path.join(self.filelist_dir, container+'.txt')
        if os.path.exists(filelist_path):
            if not overwrite_filelist:
                return filelist_path
        has_rucio = any('RUCIO' in k for k in os.environ.keys())
        has_voms = any('VOMS' in k for k in os.environ.keys()) # does not take into account expired token
        filelist_path = os.path.join(self.filelist_dir, container+'.txt')
        if not has_rucio or not has_voms:
            raise EnvironmentError("Invalid environment: please 'lsetup rucio' and 'voms-proxy-init -voms atlas'")

        cmd = "rucio list-file-replicas --rse {rse:s} {container:s} | grep {rse:s}".format(**{'rse':self.rse,
                                                                                              'container':container })
        def clean_line(line, rse, prefix_from, prefix_to):
            """
            Convert output line that looks like:
            | user.prose | user.prose.8949257._000001.out.root | 3.4 GB     | 22acf9ae  | CERN-PROD_SCRATCHDISK: gsiftp://eosatlassftp.cern.ch:2811/eos/atlas/atlasscratchdisk/rucio/user/prose/6d/a7/user.prose.8949257._000001.out.root |
            into a line that looks like:
            root://eosatlas//eos/atlas/atlasscratchdisk/rucio/user/prose/6d/a7/user.prose.8949257._000001.out.root
            """
            fields = [f.strip() for f in line.split('|')]
            file_column = next((f for f in fields if rse in f), None)
            file_path = next((f.strip() for f in file_column.split() if prefix_from in f), None)
            return re.sub(r'.*'+prefix_from, prefix_to, file_path, 1)
        out = utils.get_command_output(cmd)
        if out['returncode']:
            raise IOError("Command failed: '%s'\nstdout:\n%s\nstderr:\n%s" %
                          (cmd, out['stdout'], out['stderr']))
        else:
            lines = [l for l in out['stdout'].split('\n') if self.rse in l]
            filenames = [clean_line(l, self.rse, self.root_prefix_placeholder, self.root_prefix)
                         for l in lines]
            with open(filelist_path, 'w') as filelist_file:
                filelist_file.write('\n'.join(filenames))
        return filelist_path
#___________________________________________________________

class RucioEosCernInterface(RseInterface):
    "Access files on CERN-PROD_SCRATCHDISK through eos"
    def __init__(self, filelist_dir='VLQAnalysis/data/filelist/eos',
                 rse='CERN-PROD_SCRATCHDISK',
                 root_prefix='root://eosatlas//eos/atlas',
                 root_prefix_placeholder='/eos/atlas'):
        super(RucioEosCernInterface, self).__init__(filelist_dir, rse, root_prefix, root_prefix_placeholder)

#___________________________________________________________

class RucioPnfsIfaeInterface(RseInterface):
    "Access files on IFAE_SCRATCHDISK through pnfs"
    def __init__(self, filelist_dir='VLQAnalysis/data/filelist/pnfs',
                 rse='IFAE_SCRATCHDISK',
                 root_prefix='root://xrootd.pic.es//pnfs/pic.es',
                 root_prefix_placeholder='/pnfs/pic.es'):
        super(RucioPnfsIfaeInterface, self).__init__(filelist_dir, rse, root_prefix, root_prefix_placeholder)

#___________________________________________________________

if __name__=='__main__':
    print "Testing sample catalogues"

    # print "build catalogue from Peyton's file:"
    # sc = SampleCatalogue()
    # sc.verbose = True
    # sc.add_samples_from_file(path='VLQAnalysis/data/samples_HtX4TopsNtuple-00-00-11.txt')
    # print "collected %d samples" % len(sc.samples)
    # sc.categorise_samples(sc.samples) # only for specialised catalogues

    # -- tested: ok
    # print 'samples:'
    # for s in sc.samples:
    #     print s

    # -- tested: ok
    # sc.write_script_to_generate_lists(output_directory='VLQAnalysis/data/hbsm/filelist/eos/', rse='CERN-PROD_SCRATCHDISK')

    # -- tested: ok, all categorised
    # print "%d categorised samples" % len([s for s in sc.samples if s.group])
    # uncategorised_samples = [s for s in sc.samples if not s.group]
    # if uncategorised_samples:
    #     print "still %d uncategorside samples" % len(uncategorised_samples)
    #     print '\n'.join(s.full_name for s in uncategorised_samples)

    # -- tested: ok (go from one list to group files and back)
    sc = HbsmSampleCatalogue()
    # sc = VlqSampleCatalogue()
    sc.verbose = True
    sc.add_samples_from_file(path='VLQAnalysis/data/samples_HtX4TopsNtuple-00-00-12.txt')
    sc.categorise_samples(sc.samples) # only for specialised catalogues
    sc.write_group_files()
    sc2 = SampleCatalogue()
    sc2.add_samples_from_group_files(glob.glob(sc.groupfiles_directory+'/*.txt'))
    print "%d samples from production file, and %d samples from group files" % (len(sc.samples), len(sc2.samples))

    # -- tested: ok (also the ttbar ht + hf splitting)
    # groupfiles_directory = 'VLQAnalysis/data/groups/hbsm'
    # sc_hbsm = HbsmSampleCatalogue()
    # sc_hbsm.add_samples_from_group_files(glob.glob('VLQAnalysis/data/groups/hbsm/*.txt'))
    # print "%d samples from group files" % (len(sc_hbsm.samples))
    # sc_hbsm.samples = sc_hbsm.add_systematic_variations(sc_hbsm.samples)
    # print "%d samples after syst variations" % (len(sc_hbsm.samples))
    # ttbar_samples = sc_hbsm.samples_from_group('ttbar')
    # for s in ttbar_samples:
    #     print s.short_name,' ',s.full_name

    # -- tested: ok for both eos and disk
    sc_hbsm = HbsmSampleCatalogue()
    # sc_hbsm.add_samples_from_group_files(glob.glob('VLQAnalysis/data/groups/hbsm/*.txt'))
    sc_hbsm.add_samples_from_group_files(glob.glob(sc_hbsm.groupfiles_directory+'/hbsm.txt'))
    sc_hbsm.samples = sc_hbsm.add_systematic_variations(sc_hbsm.samples)
    input_from_dir = LocalDiskInterface(filelist_dir='VLQAnalysis/data/filelist',
                                        base_input_dir='/tmp/gerbaudo/rucio')
    input_from_eos = RucioEosCernInterface()
    def print_filelists(samples):
        for sample in samples:
            for systematic in sample.systematic_uncertainties:
                for variation in [v for v in systematic.variations if v.name=='nominal']:
                    print "%s %s : %s" % (variation.name, sample.full_name, variation.filelist)
    try:
        print_filelists(sc_hbsm.samples)
    except IOError:
        print "Missing filelists, generating them"
        sc_hbsm.add_filelists(samples=sc_hbsm.samples, input_interface=input_from_eos)
    print_filelists(sc_hbsm.samples)
